{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "style = \"<style>svg{width:70% !important;height:70% !important;}</style>\"\n",
    "HTML(style)\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Начнём с простого - создайте Decision Tree классификатор, используя одноимённый класс из библиотеки sklearn и сохраните его в переменную dt.\n",
    "\n",
    "У дерева должны быть следующие параметры:\n",
    "максимальная глубина - 5 уровней\n",
    "минимальное число образцов в вершине для разделения - 5\n",
    "\n",
    "Подробнее узнать об имеющихся параметрах Decision Tree можно узнать в документации."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(max_depth=5, min_samples_split=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Получил Поскалку))\n",
    "Отличный вариант решения, а тут и вторая пасхалочка!\n",
    "https://stepik.org/invitation/28197afd3258d206bbb410fe79e36bcf4678e1b7/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Вопрос 1\n",
    "Скачайте набор данных с тремя переменными: sex, exang, num. Представьте, что при помощи дерева решений мы хотим классифицировать есть или нет у пациента заболевание сердца (переменная num), основываясь на двух признаках: пол (sex) и наличие/отсутсвие стенокардии (exang). Обучите дерево решений на этих данных, используйте entropy в качестве критерия.\n",
    "Укажите, чему будет равняться значение Information Gain для переменной,  которая будет помещена в корень дерева.\n",
    "В ответе необходимо указать число с точностью 3 знака после запятой."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "   sex  exang  num\n0    1      1    1\n1    1      1    1\n2    1      0    1\n3    1      0    0\n4    1      0    1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>exang</th>\n      <th>num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_data_tree.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(criterion='entropy')"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['sex', 'exang']]\n",
    "y = df.num\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.SVG object>",
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"494pt\" height=\"314pt\" viewBox=\"0.00 0.00 494.00 314.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 490,-310 490,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\"><title>0</title>\n<polygon fill=\"#fbede3\" stroke=\"black\" points=\"304,-306 186,-306 186,-223 304,-223 304,-306\"/>\n<text text-anchor=\"middle\" x=\"245\" y=\"-290.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">exang &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"245\" y=\"-275.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.996</text>\n<text text-anchor=\"middle\" x=\"245\" y=\"-260.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 238</text>\n<text text-anchor=\"middle\" x=\"245\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [128, 110]</text>\n<text text-anchor=\"middle\" x=\"245\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = not_num</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\"><title>1</title>\n<polygon fill=\"#f1bc96\" stroke=\"black\" points=\"237.5,-187 126.5,-187 126.5,-104 237.5,-104 237.5,-187\"/>\n<text text-anchor=\"middle\" x=\"182\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sex &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.903</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 157</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [107, 50]</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = not_num</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\"><title>0-&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M223.142,-222.907C218.451,-214.195 213.444,-204.897 208.596,-195.893\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"211.642,-194.166 203.819,-187.021 205.478,-197.485 211.642,-194.166\"/>\n<text text-anchor=\"middle\" x=\"196.635\" y=\"-207.266\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\"><title>4</title>\n<polygon fill=\"#7ebfee\" stroke=\"black\" points=\"362,-187 256,-187 256,-104 362,-104 362,-187\"/>\n<text text-anchor=\"middle\" x=\"309\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sex &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.826</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 81</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [21, 60]</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = num</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\"><title>0-&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M267.204,-222.907C271.97,-214.195 277.056,-204.897 281.981,-195.893\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"285.106,-197.474 286.835,-187.021 278.965,-194.114 285.106,-197.474\"/>\n<text text-anchor=\"middle\" x=\"293.86\" y=\"-207.313\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\"><title>2</title>\n<polygon fill=\"#ea975c\" stroke=\"black\" points=\"110,-68 0,-68 0,-0 110,-0 110,-68\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.612</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 53</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [45, 8]</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = not_num</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\"><title>1-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M134.71,-103.726C123.814,-94.3318 112.236,-84.349 101.379,-74.9883\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"103.481,-72.1789 93.6215,-68.2996 98.9096,-77.4804 103.481,-72.1789\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\"><title>3</title>\n<polygon fill=\"#f7d6bf\" stroke=\"black\" points=\"238,-68 128,-68 128,-0 238,-0 238,-68\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.973</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 104</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [62, 42]</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = not_num</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\"><title>1-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M182.372,-103.726C182.447,-95.5175 182.526,-86.8595 182.602,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186.104,-78.3312 182.696,-68.2996 179.105,-78.2672 186.104,-78.3312\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\"><title>5</title>\n<polygon fill=\"#b0d8f5\" stroke=\"black\" points=\"362,-68 256,-68 256,-0 362,-0 362,-68\"/>\n<text text-anchor=\"middle\" x=\"309\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.954</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [6, 10]</text>\n<text text-anchor=\"middle\" x=\"309\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = num</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\"><title>4-&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M309,-103.726C309,-95.5175 309,-86.8595 309,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"312.5,-78.2996 309,-68.2996 305.5,-78.2996 312.5,-78.2996\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\"><title>6</title>\n<polygon fill=\"#74baed\" stroke=\"black\" points=\"486,-68 380,-68 380,-0 486,-0 486,-68\"/>\n<text text-anchor=\"middle\" x=\"433\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">entropy = 0.779</text>\n<text text-anchor=\"middle\" x=\"433\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 65</text>\n<text text-anchor=\"middle\" x=\"433\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [15, 50]</text>\n<text text-anchor=\"middle\" x=\"433\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = num</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\"><title>4-&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M355.173,-103.726C365.811,-94.3318 377.116,-84.349 387.716,-74.9883\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"390.112,-77.5424 395.291,-68.2996 385.478,-72.2953 390.112,-77.5424\"/>\n</g>\n</g>\n</svg>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = Source(tree.export_graphviz(clf, out_file=None, feature_names=list(X),\n",
    "                                    class_names=['not_num', 'num'], filled=True))\n",
    "display(SVG(graph.pipe(format='svg')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "0.11920588235294105"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IG = 0.996 - (n0*E0 + n1*E1)/N\n",
    "# n0 - чило сэмплов слева, n1 - число сэмплов справа, E0 - энтропия слева, Е1 - энтропия справа. N = n0+n1\n",
    "ig = 0.996 - (157*0.903 + 81*0.826)/(157 + 81)\n",
    "ig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# в pic/ig.png лежат формулы полезные для этого урпжанения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь, создав дерево, давайте обучим его и попробуем что-нибудь предсказать!\n",
    "\n",
    "Для начала опробуем наше дерево на классическом наборе iris, где собраны данные о длине, ширине чашелистиков и лепестков ирисов и их принадлежности к виду. В sklearn он уже встроен, что довольно удобно.\n",
    "\n",
    "Итак, вам даны 2 numpy эррея с измеренными признаками ирисов и их принадлежностью к виду. Сначала попробуем примитивный способ с разбиением данных на 2 датасэта. Используйте функцию train_test_split для разделения имеющихся данных на тренировочный и тестовый наборы данных, 75% и 25% соответственно.\n",
    "Затем создайте дерево dt с параметрами по умолчанию и обучите его на тренировочных данных, а после предскажите классы, к которым принадлежат данные из тестовой выборки, сохраните результат предсказаний в переменную predicted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "   sepal_length  sepal_width  petal_length  petal_width  species\n0           5.1          3.5           1.4          0.2        0\n1           4.9          3.0           1.4          0.2        0\n2           4.7          3.2           1.3          0.2        0\n3           4.6          3.1           1.5          0.2        0\n4           5.0          3.6           1.4          0.2        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('data/iris.csv', index_col=0)\n",
    "iris.columns = iris.columns.str.replace(' ', '_')\n",
    "iris.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "X = iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = iris[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "sepal_length    float64\nsepal_width     float64\npetal_length    float64\npetal_width     float64\ndtype: object"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "species    int64\ndtype: object"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier()"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1,\n       0, 2, 2, 2, 2, 1, 1, 0, 0, 0, 2, 0, 2, 1, 1, 0], dtype=int64)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = dt.predict(X_test)\n",
    "predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание на сопоставление значений из двух списков"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cross_validate - Разделение данных на k частей, тренировка на k−1 частях, тестирование на оставшейся; так для каждой части\n",
    "train_test_split - Разделение имеющихся данных на тестовый и тренировочный наборы\n",
    "LeaveOneOut - Разделение данных на 2 части с n−1 и 1 наблюдением, на первой идёт тренировка, 2-ая - для предсказания; каждое наблюдение побывает во второй части\n",
    "ShuffleSplit - Аналог обычного разделения на тестовый и тренировочный датасэты с большим числом таких случайных разделений\n",
    "LeavePOut - Разделение данных на 2 части с n−k и k наблюдениями, на первой идёт тренировка, 2-ая - для предсказания; идёт ротация по всем наблюдениям\n",
    "StratifiedKFold - k-fold cross validation с учётом количества наблюдений в классах"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Расположите элементы списка в правильном порядке"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В продолжение предыдущего вопроса - расположите разные стратегии разделения данных для кросс-валидации по затратам вычислительных мощностей на последующие предсказания. Сверху самый быстрый и требующий меньше всего вычислений для валидации:\n",
    "\n",
    "1 split on train and test sets\n",
    "2 k-fold cross validation\n",
    "3 leave one out\n",
    "\n",
    "Правильно! Такой порядок связан с количеством последующих прогонов через модель: в обычном сплите получается всего 1 пара train и test datasets, в k-fold кросс-валидации их будет уже k, а в leave-one-out - по числу наблюдений."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# шаг 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Существуют различные способы вызова кросс-валидации в sklearn, например\n",
    "\n",
    "cross_val_predict(estimator, x, y, cv=bar)\n",
    "где estimator - предсказывающая модель, а bar - число блоков при k-fold кросс-валидации или объект из sklearn.model_selection, позволяющий осуществлять кросс-валидацию по другой стратегии.\n",
    "Мы будем использовать другой способ - GridSearchCV, отбирающий лучшую модель по заданным параметрам, проводя кросс-валидацию."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Одно дерево - хорошо, но где гарантии, что оно является лучшим, или хотя бы близко к нему? Одним из способов найти более-менее оптимальный набор параметров дерева является перебор множества деревьев с разными параметрами и выбор подходящего.\n",
    "Для этой цели существует класс GridSearchCV, перебирающий каждое из сочетаний параметров среди заданных для модели, обучающий её на данных и проводящих кросс-валидацию. После этого в аттрибуте .best_estimator_ храниться модель с лучшими параметрами.\n",
    "Это применимо не только к деревьям, но и к другим моделям sklearn.\n",
    "\n",
    "Теперь задание - осуществите перебор всех деревьев на данных ириса по следующим параметрам:\n",
    "максимальная глубина - от 1 до 10 уровней\n",
    "минимальное число проб для разделения - от 2 до 10\n",
    "минимальное число проб в листе - от 1 до 10\n",
    "и сохраните в переменную best_tree лучшее дерево. Переменную с GridSearchCV назовите search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 10), 'cv': range(1, 10)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter cv for estimator DecisionTreeClassifier(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-74-d12e3c67f14e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mbest_tree\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDecisionTreeClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0msearch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbest_tree\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparameters\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0msearch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0msearch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    839\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    840\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 841\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    842\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    843\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1286\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1287\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1288\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1289\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1290\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    793\u001B[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001B[0;32m    794\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 795\u001B[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001B[0m\u001B[0;32m    796\u001B[0m                                                        \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    797\u001B[0m                                                        \u001B[0mtrain\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1039\u001B[0m             \u001B[1;31m# remaining jobs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1040\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1041\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    857\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 222\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    579\u001B[0m             \u001B[0mcloned_parameters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msafe\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    580\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 581\u001B[1;33m         \u001B[0mestimator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mcloned_parameters\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    582\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    583\u001B[0m     \u001B[0mstart_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36mset_params\u001B[1;34m(self, **params)\u001B[0m\n\u001B[0;32m    228\u001B[0m             \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msub_key\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpartition\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'__'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mvalid_params\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 230\u001B[1;33m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001B[0m\u001B[0;32m    231\u001B[0m                                  \u001B[1;34m'Check the list of available parameters '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    232\u001B[0m                                  \u001B[1;34m'with `estimator.get_params().keys()`.'\u001B[0m \u001B[1;33m%\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid parameter cv for estimator DecisionTreeClassifier(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "best_tree = tree.DecisionTreeClassifier()\n",
    "search = GridSearchCV(best_tree, parameters)\n",
    "search.fit(X, y)\n",
    "search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Чужие решения"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Инициализация Дерева\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Словарь параметров для Дерева и их диапазоном значений\n",
    "dt_params = {'max_depth': range(1, 11), 'min_samples_split': range(2, 11), 'min_samples_leaf': range(1, 11)}\n",
    "\n",
    "# Обучение Дерева с перебором значений параметров\n",
    "search = GridSearchCV(dt, param_grid=dt_params, cv=5)\n",
    "search.fit(X, y)\n",
    "\n",
    "# Дерево с лучшим сочетаением параметров\n",
    "best_tree = search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Шаг 9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чем больше данных, сложность модели и число её параметров, тем дольше будет вестись поиск GridSearchCV. Однако бывают случаи, когда модель нужна здесь и сейчас, и для этого есть RandomizedSearchCV! Пробегаясь по рандомной подвыборке параметров, он ищет наиболее хорошую модель и делает это быстрее полного перебора параметров, хотя и может пропустить оптимальные параметры.\n",
    "\n",
    "Здесь можно посмотреть на сравнение этих поисков.\n",
    "\n",
    "Осуществим поиск по тем же параметрам что и в предыдущем задании с помощью RandomizedSearchCV\n",
    "\n",
    "максимальная глубина - от 1 до 10 уровней\n",
    "минимальное число проб для разделения - от 2 до 10\n",
    "минимальное число проб в листе - от 1 до 10\n",
    "Cохраните в переменную best_tree лучшее дерево. Переменную с RandomizedSearchCV назовите search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "params = {'max_depth': range(1, 11), 'min_samples_split': range(2, 11), 'min_samples_leaf': range(1, 10)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "search = RandomizedSearchCV(dt, params)\n",
    "search.fit(X, y)\n",
    "best_tree = search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=6, min_samples_split=5)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Шаг 10\n",
    "Воспользуемся изученными приёмами и попредсказываем!\n",
    "\n",
    "Даны 2 датасэта, к которым вы можете обращаться:\n",
    "\n",
    "    train - размеченный с известными правильным ответами (хранятся в колонке y)\n",
    "    test - набор, где нужно предсказать их\n",
    "Найдите дерево с наиболее подходящими параметрами с помощью GridSearchCV и предскажите с его помощью ответы ко 2-ому сэту! Границы параметров как раньше:\n",
    "\n",
    "    максимальная глубина - от 1 до 10 уровней\n",
    "    минимальное число проб для разделения - от 2 до 10\n",
    "    минимальное число проб в листе - от 1 до 10\n",
    "Названия переменных тоже:лучшее дерево - best_tree, GridSearchCV - search, а предсказания - predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "   sepal_length  sepal_width  petal_length  petal_width\n0           5.1          3.5           1.4          0.2\n1           4.9          3.0           1.4          0.2\n2           4.7          3.2           1.3          0.2\n3           4.6          3.1           1.5          0.2\n4           5.0          3.6           1.4          0.2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# эксперименты над уже подгруженными данными, чтобы безошибочно решить с предложенными в задании.\n",
    "train = iris\n",
    "X = train.drop('species', axis='columns')\n",
    "y = train.species\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# моё решение\n",
    "X = train.drop('y', axis='columns')\n",
    "y = train.y\n",
    "params = {'max_depth': range(1, 11), 'min_samples_split': range(2, 11), 'min_samples_leaf': range(1, 10)}\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "search = GridSearchCV(dt, params)\n",
    "search.fit(X, y)\n",
    "predictions = search.predict(test)\n",
    "best_tree = search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# лучшее решение\n",
    "\n",
    "#processing parameters\n",
    "X = train.drop('y', axis='columns')\n",
    "y = train.y\n",
    "\n",
    "params = {'max_depth': range(1, 11),\n",
    "          'min_samples_split': range(2, 11),\n",
    "          'min_samples_leaf': range(1, 10)}\n",
    "\n",
    "#model preprocessing\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "search = GridSearchCV(dt, params)\n",
    "\n",
    "#model learning\n",
    "search.fit(X, y)\n",
    "best_tree = search.best_estimator_\n",
    "\n",
    "#model prediction\n",
    "predictions = best_tree.predict(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Чужие решения"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# разбиваем датафрейм train на X и y\n",
    "x_train = train.drop([\"y\"], axis=1)\n",
    "y_train = train[\"y\"]\n",
    "\n",
    "# создаем словарь с параметрами, которые хотим проверить\n",
    "params = {\"max_depth\": range(1,11), \"min_samples_split\":range(2,11), \"min_samples_leaf\":range(1,11)}\n",
    "\n",
    "# создаем экзмпляр дерева\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# создаем экземпляр GridSearchCV\n",
    "search = GridSearchCV(dt, params, cv=5)\n",
    "\n",
    "# обучаем или ищем лучшее дерево\n",
    "search.fit(x_train,y_train)\n",
    "\n",
    "# сохраням лучшее дерево по мнению GridSearchCV\n",
    "best_tree = search.best_estimator_\n",
    "\n",
    "# делаем предсказания по лучшему дереву на датасете test\n",
    "predictions = best_tree.predict(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Тут интересный drop.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = train.drop(columns='y')\n",
    "y = train['y']\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf\n",
    "parametrs = {'max_depth': range(1, 10), 'min_samples_leaf': range(1, 10), 'min_samples_split': range(2, 10)}\n",
    "search = GridSearchCV(clf, parametrs, cv=5)\n",
    "search.fit(X, y)\n",
    "best_tree = search.best_estimator_\n",
    "predictions = best_tree.predict(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Импортируем необходимые модули.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "# Создадим переменную, по которой будем строить дерево решений (подмножество train).\n",
    "X_train = train.drop(['y'], axis=1)\n",
    "# Создадим переменную с известными правильным ответами, которую будем предсказывать при настройке дерева решений.\n",
    "y_train = train.y\n",
    "# Создадим переменную, на которой будем строить предсказание с помощью обученного дерева решений (подмножество test).\n",
    "X_test = test\n",
    "#\n",
    "# Создадим дерево решений с параметрами по умолчанию.\n",
    "dt = DecisionTreeClassifier()\n",
    "#\n",
    "# Проведем обучение моделей на подмножестве train.\n",
    "parametrs = {'criterion': ['gini', 'entropy'], 'min_samples_split': range(2, 11),\n",
    "             'min_samples_leaf': range(1, 11), 'max_depth': range(1, 11)}\n",
    "search = GridSearchCV(dt, parametrs)\n",
    "search.fit(X_train, y_train)\n",
    "#\n",
    "# Определение наилучшего дерева решений.\n",
    "best_tree = search.best_estimator_\n",
    "#\n",
    "# Предскажем с помощью наилучшего дерева ответы ко 2-ому сэту (test).\n",
    "predictions = best_tree.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Шаг 13\n",
    "При классификации модель может допускать ошибки, присваивая наблюдению неверный класс. Существуют различные метрики оценки качества предсказаний, которые базируются на 4-ёх параметрах - true positive, false positive, false negative и true negative, соответствующих тому какой класс был присвоен наблюдениям каждого из классов. Матрицу из 4-ёх (в случае бинарной классификации) этих параметров называют confusion matrix.\n",
    "\n",
    "В sklearn можно её удобно получить с помощью функции confusion_matrix. Вам даны 2 эррея с истинными классами наблюдений и предсказанными - y и predictions. Получите по ним confusion matrix и поместите её в переменную conf_matrix."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-87-3397d0375889>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mconf_matrix\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Шаг 14"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм.\n",
    "\n",
    "Recall демонстрирует способность алгоритма обнаруживать данный класс вообще, а precision — способность отличать этот класс от других классов.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ошибки классификации бывают двух видов: False Positive и False Negative. В статистике первый вид ошибок называют ошибкой I-го рода, а второй — ошибкой II-го рода"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Precision и recall не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}